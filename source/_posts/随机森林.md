title: 随机森林
date: 2018/11/15
categories:

- 数据处理
- 机器学习
tags:
-    随机森林
comments: true
---
1. [集成算法-随机森林](https://github.com/apachecn/MachineLearning/blob/master/docs/5.Logistic%E5%9B%9E%E5%BD%92.md)
    - **描述**：**分类算法**，随机森林是指随机抽出一些样本集，去训练出多棵决策树，最后新数据被多棵决策树判断类别，新数据类别取多数者。随机是指对训练数据集的随机抽取，对特征的随机抽取；森林是指多棵决策树。
    - **原理解释**，结合例子：**声呐信号分类**
    1. **准备数据**
        ```
        样本1：0.02,0.0371,0.0428,0.0207, .....,0.0032,R
        样本2：0.0453,0.0523,0.0843,0.0689, ...., 0.0044,R
        样本3：0.0262,0.0582,0.1099,0.1083,.....,0.0078,M
        .....
        样本n: 0.026,0.0363,0.0136,0.0272,......,0.0115,M
        ```
    2. 把数据集，分成 n_folds 份样本集，采用无放回抽取。
        ```
        dataset: [[样本1],[样本2],[样本3],[样本4], .... ,[样本n],]
        
        第1份：[[样本2],[样本5],[样本89],[样本34], ... ,[样本x1]]
        第2份：[[样本3],[样本51],[样本389],[样本324], ... ,[样本x2]]
        ...
        第n_fols份：[[样本21],[样本45],[样本89],[样本34], ... ,[样本xn]]
        
        ```
    3. **交叉验证**
        ```
        总样本集：[[样本集1], [样本集2],...,[样本集n_folds]]
        
        取样本集1 为测试数据，剩下的样本集为训练数据
        train = [[样本集2],...,[样本集n_folds]]
        test = [[样本集1]]
        整理一下：train = sum(train, [])
        ----->  把列表里面的列表取消掉
        
        取样本集2 为测试数据，剩下的样本集为训练数据
         
        取样本集3 为测试数据，剩下的样本集为训练数据
        
        ......
        
        取样本集n_folds 为测试数据，剩下的样本集为训练数据
        
        这样就叫做交叉验证
        ```
    4. **训练决策树**
        ```
        设置决策树的深度 max_depth，叶子结点数 min_size
        生成决策树的个数 n_trees， 选取特征的个数 n_features
        
        1. 回想生成决策树的算法
          传入训练数据 train = sum(train, [])
        
        2. 从全部的数据集特征中，随机选取特征 n_features 个
           决策树选取最优的特征、特征值，涉及 gini 的概念。
           
           比如选取第一个特征，进行分子集，由于每个样本的特征值此时不同
           遍历全部的特征值， 小于归左子树，大于归右子树。
           获得 gini 值 最小的 最优特征、特征值。
           
        3. max_depth, 设置树深度可以提前结束递归，建立决策树
           防止过拟合
        
        4. min_size
        ```
    5. 测试测试集，交叉验证n_folds 次
    6. 声呐信号分类的结果
        ```
        设置: n_folds = 5
              n_trees = 10
             max_depth = 20
             min_size = 1
        
        结果：
        决策树1   决策树2    .......    决策树10
        
        Trees: 10
        
        五份准确率：
        Scores: [85.71428571428571, 83.33333333333334,
        80.95238095238095, 85.71428571428571, 90.47619047619048]
        
        Mean Accuracy: 85.238%
        
        random= 0.13436424411240122
        ```

          


欢迎大家给我留言，提建议，指出错误，一起讨论学习技术的感受！