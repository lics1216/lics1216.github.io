title: 朴素贝叶斯
date: 2018/11/11
categories:

- 数据处理
- 机器学习
tags:
-   朴素贝叶斯
comments: true
---

#### 朴素贝叶斯
朴素贝叶斯是分类算法，一个新数据x出现，是类a的概率为$p(a/x)$，属于类b概率$p(b/x)$
* 若$p(a/x) > p(b/x)$，则x归为类a
* 若$p(a/x) < P(b/x)$，则为类b

要直接比较 $p(a/x)$， $p(b/x)$ 的大小是很难的，我们可借助条件概率进行转化。先理解什么是条件概率，
$$p(a/x) = {p(a,x)  \over p(x)} $$

这样就可以得乘法公式，
$$p(a,x) = p(a/x)p(x)$$

再把$p(a/x)$进行转换可得，
$$p(a/x) = {p(a,x) \over p(x)} = {p(x,a) \over p(x)} = {p(x/a)p(a) \over p(x)}$$

因此比较就变成了
$$p(a/x) = {p(x/a)p(a) \over p(x)}$$
$$p(b/x) = {p(x/b)p(b) \over p(x)}$$

要比较他们的大小，就是计算出
* $p(a)$，类别a出现的概率
* $p(b)$，类别b出现的概率
* $p(x/a)$，类别a出现时样本x出现的概率
* $p(x/b)$，类别b出现时样本x出现的概率

#### 应用
接下来用朴素贝叶斯在文本分类，屏蔽社区留言板的侮辱性言论的应用作为例子，解释上面四个概率的求法。假设数据集如下
```
# 言论集
postingList = [
['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], 
['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],
['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],
['stop', 'posting', 'stupid', 'worthless', 'garbage'],
['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],
['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']
]

# 1代表侮辱性言论，0 非侮辱性
classVec = [0, 1, 0, 1, 0, 1]
```

要判断一个样本数据是否侮辱性言论，先统计全部言论去重之后的词汇，再得出每条言论基于全部词汇的词频矩阵
```
词汇集= ['word1','word2',‘word3’..,'wordn']

# 第一列的2代表word1在言论1中出现2次
言论1：  [2, 0, 1, ....,4]
言论2：  [3, 2, 0, ....,2]   
......
言论n：  [0, 2, 2, ....,0]   

总侮辱言论：[45, 122, 232, 0,.....,90]
总非侮辱言论：[123, 23, 23, 2,.....,23]
```

假设a类别为侮辱性言论，b类别为非侮辱性言论，言论总数为N，a总数量n1，b总数量n2。此时可以求得，
*  $p(a) = {n1 \over N}$
*  $p(b) = {n2 \over N}$

至于$p(x/a)$，要求a类别出现时x样本出现的概率，x是由很多词汇构成的。**朴素贝叶斯算法的朴素二字正是假设各个特征之间是相互独立的，即每个词汇的出现是不会相互影响的；并且认为每个特征同等重要。**因此求得侮辱性言论出现时每个词汇出现的概率为
```
# n0=sum([45, 122, 232, 0,.....,90]),即侮辱性言论集中总词数
[45, 122, 232, 0,.....,90]/n0
```

假设x样本包含词汇为 xword1,xword2,....xwordi...xwordn，侮辱性言论出现时对应词汇出现的概率为p(xword1)，p(xword2)，p(xwordi).......p(xwordn)
$$p(x/a) = p(xword1)p(xword2)...p(xwordi)...p(xwordn)$$

同理可得$p(x/b)$，至以上四个概率都是已知量。这样就可以用朴素贝叶斯模型进行分类。要注意的是，防止有词汇概率为 0， 词汇计数初始值1，总词汇初始值2，即
```
[45, 122, 232, 0,.....,90]+1 / (n0+2)
```

防止$p(xword1)p(xword2)...p(xwordi)...p(xwordn)=0$，采用自然对数
        

欢迎大家给我留言，提建议，指出错误，一起讨论学习技术的感受！