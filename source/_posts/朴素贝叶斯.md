title: 朴素贝叶斯
date: 2018/11/11
categories:

- 数据处理
- 机器学习
tags:
-   朴素贝叶斯
comments: true
---

1. [朴素贝叶斯](https://github.com/apachecn/MachineLearning/blob/master/docs/4.%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF.md)
    - **描述**：分类算法，一个新数据出现，是类A的概率为P(A)，属于类B概率p(B)，若p(A) > p(B)，则新数据归A类，反之B类
    - **应用**：文本分类，屏蔽社区留言板的侮辱性言论
    1. 公式推导
        - 条件概率公式
        ```math
        p(x/c) = p(x,c)/p(c)
        ```
        - 乘法公式
        ```math
        p(x,c) = p(x/c)P(c)
        ```
        - 贝叶斯公式
        ```math
        p(c/x) = p(c,x)/p(x) = P(x,c)/p(x) = p(x/c)p(c)/p(x)
        
        p(c/x) = p(x/c)p(c)/p(x)
        ```
    2. 算法应用
        ```math
        
        p(c1/w) = p(w/c1)p(c1)/p(w)
        ```
        ```math
        
        p(c0/w) = p(w/c0)p(c0)/p(w)
        ```
        ```
        p(c1/w) 代表 w言论出现时为侮辱性言论c1的概率，c0 代表非侮辱性
        判断w是c1 或者 c0 ， 实则比较 p(c1/w)，p(c0/w)大小
        比较等式右边，分母相同，比较  p(w/c1)p(c1)， p(w/c0)p(c0)
        
        p(w/c1)代表 侮辱性言论出现该新言论的概率，下面详细解释
        p(c1) 出现侮辱性言论的概率
        ```
    3. 收集数据：
        ```
        postingList = [['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], 
                       ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],
                       ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],
                       ['stop', 'posting', 'stupid', 'worthless', 'garbage'],
                       ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],
                       ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]
        classVec = [0, 1, 0, 1, 0, 1]
        假设每一行是一条言论
        classvec 代表言论类别
        ```
    4. 准备数据：
        - 统计全部言论，去重之后的词汇，词汇集= ['词1','词2',...,'词n']
        - 对每条言论，基于词汇集， 统计每个词出现次数， 未出现写0，出现+1 
        - 分类侮辱性言论、非侮辱性言论来统计，出现词数量
        ```
        词汇集： ['词1'，'词2','词3','词4',....,'词n']
        言论1：  [2, 0, 1, 9,....,4]
        言论2：  [3, 2, 0, 0,....,2]   
        ......
        言论n：  [0, 2, 2, 2,....,0]   
        
        总侮辱言论：[45, 122, 232, 0,.....,90]
        总非侮辱言论：[123, 23, 23, 2,.....,23]
        
        侮辱性言论各个词出现概率：总侮辱言论/总侮辱言论中出现的词汇总个数n1， [45, 122, 232, 0,.....,90]/n1
        即下面的 [p(F1/c1)、p(F2/c1)、....p(Fn/c1)]
        
        非侮辱性言论各个词出现概率：总侮辱言论/总侮辱言论中出现的词汇总个数n0，[123, 23, 23, 2,.....,23]/n0
        即下面的 [p(F1/c0)、p(F2/c0)、....p(Fn/c0)]
        
        p(c1) = 总侮辱性言论数/总言论数
        p(c0) = 总非侮辱性言论数/总言论数
        
        言论1, 词1出现2次....
        p(w/c1), w言论里很多词F1、F2、F3、F4.....Fn，且这些词出现相互独立。
        p(w/c1) = p(F1/c1)p(F2/c1)....p(Fn/c1)
        p(w/c0) = p(F1/c0)p(F2/c0)....p(Fn/c0)
        
        至此，p(w/c1)p(c1), p(w/c0)p(c0)都是已知量
        ```
    5. 测试数据
        - 防止p(Fi/c1) = 0， 词汇计数初始值1，总词汇初始值2，即[123, 23, 23, 2,.....,23]+1 / (n0+2)
        - 防止p(Fi/c1) * p(Fj/c1)....p(Fk/c1) = 0，采用对数，即 log [123, 23, 23, 2,.....,23]+1 / (n0+2)
        - 上面类似矩阵数乘运算
    6. 使用算法即可

          


欢迎大家给我留言，提建议，指出错误，一起讨论学习技术的感受！