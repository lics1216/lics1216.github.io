title: 决策树
date: 2018/11/09
categories:

- 数据处理
- 机器学习
tags:
-   决策树
comments: true
---

1. [决策树](https://github.com/apachecn/MachineLearning/blob/master/docs/3.%E5%86%B3%E7%AD%96%E6%A0%91.md)
    - **描述**：

        - 分类算法：一个未贴标签(未知类别)的新数据(含多个特征)，通过问多个问题（问题是：特征，答案：是或者否），最终问题问完，判断出新数据类别。问问题的流程基于决策树。
    - **应用**：判断生物是否鱼
    - 收集数据：
    - 分析数据：使用任何方法，构造树完成之后，我们可以将树画出来。
        ``` 
        特征1（不浮出水面是否能活）    特征2（是否有脚蹼）       类别(是否鱼)
                yes                       yes                  yes
                yes                       yes                  yes
                yes                       no                   no
                no                        yes                  no
                no                        yes                  no
        
        变成向量的形式：   
        dataSet = [[1, 1, 'yes'],
                   [1, 1, 'yes'],
                   [1, 0, 'no'],
                   [0, 1, 'no'],
                   [0, 1, 'no']]
        labels = ['no surfacing', 'flippers']
        labels 存储的是特征，即决策树的问题
        ```
    - 准备数据
        1. **计算给定数据集的香农熵的函数**
        - 假设我们在特征1和特征2选特征1来分类，即问一个问题(此新数据不浮出能活吗)，安照答案(即特征值yes no )得到分类，并计算该数据集的香农商(**用于衡量此数据集混乱程度**)
        ```
           1, 1, 'yes'             0, 'no'
                                   1, 'yes' 
           1, 1, 'yes'             1, 'yes'
                        
           1, 0, 'no'  ---------->                
            
           0, 1, 'no'              1, 'no'
                                   1, 'no'
           0, 1, 'no'
             
         由特征1分类，子集去掉特征1，计算数据集香农熵
         分类前香农熵： - 2/5log(2/5) - 3/5(log3/5)    
         分类后香农熵： - 3/5*(2/3log(2/3)+1/3log(2/3))  - 2/5*(1log1)
         
         对数底为2
         香农熵越小，数据越有序
         分类前香农熵：2/5 yes 占全部类别的2/5, 3/5 同理
         分类后香农熵：3/5 表示该子集占全集，2/3表示 yes在子集占比
         若子集类别一致，香农熵为 0
         公式如下：
        ```
        ```math
        H = - p(x1)log p(x1) - p(x2)log p(x2) - ......
        ```
        2. **选择最好的数据集划分方式**
        - 当前划分数据集应采用哪个特征呢？（问哪个问题呢？）
        - 全部特征集合labels存储，逐一尝试，计算分类前后香农熵，**选取信息增益(熵差)最大的特征x**，
        - 划分后的子集去除特征x, 集合labels去除特征x
        - **递归**，**递归终止条件应理解**，构造决策树
        - 返回 `{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}`，画出决策树
        ```
              不浮出水面是否能活
                /       \
            0  /         \ 1
              /           \
             no        是否有脚蹼
                         /  \
                      0 /    \ 1
                       /      \
                      no       yes 
        ```
    - 测试决策树



欢迎大家给我留言，提建议，指出错误，一起讨论学习技术的感受！